{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Names list: https://el.wiktionary.org/w/index.php?title=%CE%9A%CE%B1%CF%84%CE%B7%CE%B3%CE%BF%CF%81%CE%AF%CE%B1:%CE%93%CF%85%CE%BD%CE%B1%CE%B9%CE%BA%CE%B5%CE%AF%CE%B1_%CE%BF%CE%BD%CF%8C%CE%BC%CE%B1%CF%84%CE%B1_(%CE%BD%CE%AD%CE%B1_%CE%B5%CE%BB%CE%BB%CE%B7%CE%BD%CE%B9%CE%BA%CE%AC)\n",
    "words = open('greek_female_names.txt', 'r').read().splitlines()\n",
    "len(words)\n",
    "min(len(w) for w in words)\n",
    "max(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'α',\n",
       " 2: 'β',\n",
       " 3: 'γ',\n",
       " 4: 'δ',\n",
       " 5: 'ε',\n",
       " 6: 'ζ',\n",
       " 7: 'η',\n",
       " 8: 'θ',\n",
       " 9: 'ι',\n",
       " 10: 'κ',\n",
       " 11: 'λ',\n",
       " 12: 'μ',\n",
       " 13: 'ν',\n",
       " 14: 'ξ',\n",
       " 15: 'ο',\n",
       " 16: 'π',\n",
       " 17: 'ρ',\n",
       " 18: 'σ',\n",
       " 19: 'τ',\n",
       " 20: 'υ',\n",
       " 21: 'φ',\n",
       " 22: 'χ',\n",
       " 23: 'ψ',\n",
       " 24: 'ω',\n",
       " 0: '.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "N = torch.zeros((26, 26), dtype=torch.int32)\n",
    "# we need a matrix for the characters to map the counts\n",
    "chars = sorted(list(set(''.join(words)))) # all chars with no duplicates\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)} # mapping chars to indexes\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'α': 1, 'β': 2, 'γ': 3, 'δ': 4, 'ε': 5, 'ζ': 6, 'η': 7, 'θ': 8, 'ι': 9, 'κ': 10, 'λ': 11, 'μ': 12, 'ν': 13, 'ξ': 14, 'ο': 15, 'π': 16, 'ρ': 17, 'σ': 18, 'τ': 19, 'υ': 20, 'φ': 21, 'χ': 22, 'ψ': 23, 'ω': 24, '.': 0}\n",
      "{1: 'α', 2: 'β', 3: 'γ', 4: 'δ', 5: 'ε', 6: 'ζ', 7: 'η', 8: 'θ', 9: 'ι', 10: 'κ', 11: 'λ', 12: 'μ', 13: 'ν', 14: 'ξ', 15: 'ο', 16: 'π', 17: 'ρ', 18: 'σ', 19: 'τ', 20: 'υ', 21: 'φ', 22: 'χ', 23: 'ψ', 24: 'ω', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "print(stoi)\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  55666\n"
     ]
    }
   ],
   "source": [
    "# OPTIMISATION PUT TOGETHER\n",
    "xs ,ys = [], []\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# initialize the 'network'\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((25,25), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.59389591217041\n",
      "3.141183376312256\n",
      "2.8456952571868896\n",
      "2.665436029434204\n",
      "2.580273389816284\n",
      "2.5274274349212646\n",
      "2.487445831298828\n",
      "2.4559385776519775\n",
      "2.4310295581817627\n",
      "2.409409284591675\n",
      "2.3920626640319824\n",
      "2.376012086868286\n",
      "2.3633131980895996\n",
      "2.35086727142334\n",
      "2.341024160385132\n",
      "2.330946445465088\n",
      "2.323150873184204\n",
      "2.3148000240325928\n",
      "2.3085553646087646\n",
      "2.301546335220337\n",
      "2.2964844703674316\n",
      "2.2905256748199463\n",
      "2.2863833904266357\n",
      "2.281270980834961\n",
      "2.2779176235198975\n",
      "2.2734832763671875\n",
      "2.2707087993621826\n",
      "2.266826629638672\n",
      "2.264556646347046\n",
      "2.261124849319458\n",
      "2.259270668029785\n",
      "2.256197929382324\n",
      "2.254654884338379\n",
      "2.2518835067749023\n",
      "2.2506284713745117\n",
      "2.248129367828369\n",
      "2.2471039295196533\n",
      "2.244802236557007\n",
      "2.2439520359039307\n",
      "2.241842746734619\n",
      "2.24117374420166\n",
      "2.2392117977142334\n",
      "2.238677740097046\n",
      "2.236845016479492\n",
      "2.236435890197754\n",
      "2.234687328338623\n",
      "2.234374523162842\n",
      "2.2327330112457275\n",
      "2.232501745223999\n",
      "2.230961561203003\n",
      "2.230830669403076\n",
      "2.2293648719787598\n",
      "2.229276418685913\n",
      "2.2278666496276855\n",
      "2.227856397628784\n",
      "2.2265090942382812\n",
      "2.226522922515869\n",
      "2.2252185344696045\n",
      "2.225290536880493\n",
      "2.2240331172943115\n",
      "2.224165201187134\n",
      "2.2229669094085693\n",
      "2.223118782043457\n",
      "2.221945285797119\n",
      "2.2221169471740723\n",
      "2.2209837436676025\n",
      "2.221207857131958\n",
      "2.220086097717285\n",
      "2.220331907272339\n",
      "2.219245195388794\n",
      "2.2195322513580322\n",
      "2.218456506729126\n",
      "2.2187576293945312\n",
      "2.2177114486694336\n",
      "2.2180330753326416\n",
      "2.2170069217681885\n",
      "2.2173471450805664\n",
      "2.216343402862549\n",
      "2.2167017459869385\n",
      "2.2157163619995117\n",
      "2.2160873413085938\n",
      "2.2151219844818115\n",
      "2.215527296066284\n",
      "2.2145919799804688\n",
      "2.2149882316589355\n",
      "2.214053153991699\n",
      "2.214466094970703\n",
      "2.2135426998138428\n",
      "2.2139668464660645\n",
      "2.213061571121216\n",
      "2.2134945392608643\n",
      "2.2125961780548096\n",
      "2.213043451309204\n",
      "2.2121615409851074\n",
      "2.212608575820923\n",
      "2.2117412090301514\n",
      "2.212195634841919\n",
      "2.2113425731658936\n",
      "2.211822986602783\n",
      "2.210958242416382\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "import torch.nn.functional as F\n",
    "\n",
    "for k in range(100):\n",
    "\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=25).float()  # input to the network: one-hot encoding\n",
    "    logits = xenc @ W  # predict log-counts\n",
    "    counts = logits.exp()  # counts, equivalent to N\n",
    "    probs = counts / counts.sum(1, keepdims=True)  # probabilities for next character\n",
    "    loss = -probs[torch.arange(num), ys].log().mean()\n",
    "    print(loss.item())\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None # set to zero the gradient\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "γη.\n",
      "γκαντριαρσαμαρω.\n",
      "καλουρικομπισαλα.\n",
      "φρεικη.\n",
      "πη.\n",
      "ματστιουλλαχκδω.\n",
      "μαμασανιαριω.\n",
      "γπανναλατογιλινχανακουρυλαναιαλατεπονσερεγιαμπαυτσοπη.\n",
      "τω.\n",
      "βσσακιννεμανω.\n",
      "ταγκρορφτιδουρατσισιαρουλα.\n",
      "κη.\n",
      "αναυ.\n",
      "ουλιτωβεσ.\n",
      "πζονου.\n",
      "κγγευ.\n",
      "εωρω.\n",
      "ζου.\n",
      "οφρωτιεννα.\n",
      "σαρα.\n",
      "μιλαστα.\n",
      "βαπη.\n",
      "κονασαρυριναφργγουλη.\n",
      "αμιφρμακαντεονα.\n",
      "ρασεριμπελα.\n",
      "αιαγελατζξατσκιδραλη.\n",
      "σσυρσαυγκατλιναλαβουναραρλδαροριταγκυλιτω.\n",
      "εναννθεραλα.\n",
      "λλειαια.\n",
      "σαρα.\n",
      "σβα.\n",
      "εφιτανημυλα.\n",
      "κρουλλοταδοριαλανω.\n",
      "α.\n",
      "πσυρια.\n",
      "ζερτενιντ.\n",
      "φυκεουλιτσχοφινζαναναναναλανανθρυλουλαναιωννασωναεω.\n",
      "τη.\n",
      "μαθειλιτστινουρουσυγινικονηρχαγουχαροζρυλαντιριναυφιανιω.\n",
      "ια.\n",
      "βργρρισαλιωραλλαγαναννα.\n",
      "υνατσα.\n",
      "φιανταινταναντσταφαχρστταραρυμαυγερετζοδα.\n",
      "τα.\n",
      "αλλικη.\n",
      "ρυμεκξτιταραρζοπη.\n",
      "ζαγδιουλαριλαλιτιαγμια.\n",
      "ελανηλλη.\n",
      "φχρεω.\n",
      "μαπεξη.\n",
      "δολανασιναμαλαλιβαλεολλειθηνθιαλευλαμαικεσναιατδελη.\n",
      "κοζπιανιανα.\n",
      "καυντανω.\n",
      "πυρανανια.\n",
      "μαμη.\n",
      "βευεβδρικωτιαγκυρα.\n",
      "φωα.\n",
      "τικριδεβελαρω.\n",
      "αριανθη.\n",
      "ιανη.\n",
      "κη.\n",
      "διτοδαμινικαθηρελλιτιννη.\n",
      "ββαλικανασω.\n",
      "φιαναλαραρου.\n",
      "βασικαιεβαμπρω.\n",
      "σσιτρ.\n",
      "αλη.\n",
      "ενστελαριασουλψραπεντα.\n",
      "α.\n",
      "μαριοσιλια.\n",
      "μενιβαονανχρτιω.\n",
      "βαρα.\n",
      "μα.\n",
      "ναναθη.\n",
      "ριλα.\n",
      "ταναμευλιλιανπανα.\n",
      "τορανιου.\n",
      "μανανυδανικαλαοδω.\n",
      "πινακμειταρνονη.\n",
      "ναιαροκω.\n",
      "ελιττιουφρουλορη.\n",
      "ξετεονδετα.\n",
      "βυ.\n",
      "ναχση.\n",
      "αναναστσασικελινεουφθετρουστρινθη.\n",
      "βεριναλυλελημελιφω.\n",
      "θετσα.\n",
      "ζπερετοριαιαεστανιαρντσα.\n",
      "βεβεριανα.\n",
      "ρσουσκιαχαινανη.\n",
      "κη.\n",
      "βα.\n",
      "μελυλψυδω.\n",
      "σα.\n",
      "φυλαλιεριδαλατουνοσχα.\n",
      "α.\n",
      "μπηδη.\n",
      "μαραννα.\n",
      "ελιαρικαναττεραλου.\n",
      "α.\n",
      "τσιντουλυλανελη.\n",
      "μαλλω.\n",
      "ποκαλιντιδειναραρουλσωριαλλα.\n",
      "σα.\n",
      "ζειοζαλιαλισα.\n",
      "οβργροιμαλουσα.\n",
      "λχρομπη.\n",
      "χρουσουφα.\n",
      "δαννια.\n",
      "μιανανικληρεριτριω.\n",
      "οπαλλγω.\n",
      "στεμιδσκανθετασιανανιανη.\n",
      "ονθητελισκυναναστστρουδια.\n",
      "α.\n",
      "χρρσειντιλιστμιανηγινδελετω.\n",
      "μαντατα.\n",
      "λα.\n",
      "χαιουλαρουρεολτσυριτσικω.\n",
      "μουμπιανανηλεν.\n",
      "αφω.\n",
      "ροζοποντινταλιαριετανια.\n",
      "αρυ.\n",
      "φυ.\n",
      "βιτη.\n",
      "ππηγελυλαυλουση.\n",
      "βαβαλχαλιευλα.\n",
      "μανα.\n",
      "νεντομπελαυριμετσουβαναραρμαμαναπιχορυσανανταργαναιαλικενοφωισταλιαισκλλανανναντγμαλιχαλαιοβαλινη.\n",
      "βναω.\n",
      "αρισορυρκινη.\n",
      "πιζιαυλλαμελεαναναλιροδανηματιδωνουρωταγαια.\n",
      "γ.\n",
      "σψηλιανανοντσουστα.\n",
      "καλεροχακατολα.\n",
      "ινα.\n",
      "μπουδωραλιτσεψκοδω.\n",
      "ιαριτευταγευλιασιτραμαστστη.\n",
      "χανανταντζωνασεμαλαρανεωνολαλασα.\n",
      "θζουρουστνιναντραναιτριζιταραρ.\n",
      "σρστζελοναταινιαρδδιουλλουξασιω.\n",
      "βανη.\n",
      "ναγανανναρανου.\n",
      "μενου.\n",
      "περωτψσταμφυνττοδουρεπυ.\n",
      "χβινη.\n",
      "δκφ.\n",
      "μαλαλγκοσα.\n",
      "χαδοξρια.\n",
      "χουριοργουσα.\n",
      "ελιτινυλαβανη.\n"
     ]
    }
   ],
   "source": [
    "# finally, sample from the 'neural net' model\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(150):\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "        # ----\n",
    "        # Before:\n",
    "        # p = P[ix]\n",
    "        # -----\n",
    "        # NOW:\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=25).float()\n",
    "        logits = xenc @ W  # predict log-counts\n",
    "        counts = logits.exp()  # counts, equivalent to N\n",
    "        p = counts / counts.sum(1, keepdims=True)  # probabilities for next character\n",
    "        # ------\n",
    "\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itos[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
